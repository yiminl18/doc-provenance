{
    "title": "Expense Control: A Gamified, Semi-Automated, Crowd-Based Approach For Receipt Capturing",
    "question": [
        "Who are the authors of this paper?",
        "Return only a list of strings, seperated by |"
    ],
    "answers": [
        "[\"Maximilian Altmeyer\", \"Pascal Lessel\", \"Antonio Kriiger\"]"
    ],
    "path": "/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc1_q1_heuristic_greedy.json",
    "context_size": 16907,
    "time": 261.2735049724579,
    "provenance": [
        "\nIUI 2016 * Social Media\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nExpense Control: A Gamified, Semi-Automated,\nCrowd-Based Approach For Receipt Capturing\n\nMaximilian Altmeyer'’, Pascal Lessel?",
        "*, Antonio Kriiger”'\n‘Saarland University, 7 DFKI GmbH, *Saarbriicken Graduate School of Computer Science\nSaarbriicken, Germany\n{first name}.",
        "{last name} @dfki.de\n\nexpense\n\nEDIT EXPENSE\n\nNektarine\n\nGeneral information Eier\n\nALPRU REISDRINK\nStore:\n\nRewe Vossko Rentier\n\nFisch Stixx\nOverall category:\nLANG.",
        "REIS KB\nGroceries\n\nAmerican pancake\n\nDate: KAKAA\n\n27.08.2015\n\nTotal sum: Goldmais\n\n1448 LEERG Mw V ST\n\nDunkle Kakaocreme\n\n‘expense\n\nexpense\n\n1,99 A\n\nexpense\n\nCROWD CORRECTIONS\n\n139€ 4 @f\nARTICLE CORRECTED FROM:\nALPRU REISDRINK to Alpro\nReisdrink\n\n0s9€ 4H 05.10.2015\n\n3 N\nao0e gw ALPRO REISORINK\nCHANGED CATEGORY OF: Kakao\n19€ oF 95.10.2015 +9 Groceries\n\nPlease name the depicted article!",
        "179€ 4 ARTICLE CORRECTED FROM:\nAlpro Reisdrink 05.10.2015 Kaa to Kakao\n045€ 48\n179€ A\nSolve Task!",
        "159€ #68\n16096 4 ff 20 tasks remaining\nee Ce)\no0s€ 4 @\n\nFigure 1: Workflow of our app.",
        "a) Photographing the receipt.",
        "b) Recognized general information.",
        "c) Extracted articles\nand categories.",
        "d) Microtask to be solved by the crowd.",
        "e) Corrections performed by the crowd\n\nABSTRACT\n\nWe investigate a crowd-based approach to enhance the out-\ncome of optical character recognition in the domain of receipt\ncapturing to keep track of expenses.",
        "In contrast to existing\nwork, our approach is capable of extracting single products\nand provides categorizations for both articles and expenses,\nthrough the use of microtasks which are delegated to an un-\npaid crowd.",
        "To evaluate our approach, we developed a smart-\nphone application based on a receipt analysis and an online\nquestionnaire in which users are able to track expenses by\ntaking photos of receipts, and solve microtasks to enhance the\nrecognition.",
        "To provide additional motivation to solve these\ntasks, we make use of gamification.",
        "In a three-week-long user\nstudy (N=12), we found that our system is appreciated, that\nour approach reduces the error rate of captured receipts sig-\nnificantly, and that the gamification provided additional mo-\ntivation to contribute more and thereby enrich the database.",
        "Author Keywords\nGamification; Crowdsourcing; Wisdom of Crowds; OCR;\nDigital Household Accounting Book\n\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full cita-\ntion on the first page.",
        "Copyrights for components of this work owned by others than\nACM must be honored.",
        "Abstracting with credit is permitted.",
        "To copy otherwise, or re-\npublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee.",
        "Request permissions from Permissions @acm.org.",
        "IUI’16, March 07-10, 2016, Sonoma, CA, USA.",
        "Copyright © 2016 ACM ISBN 978-1-4503-4137-0/16/03$15.00.",
        "DOI: http://dx.doi.org/10.1145/2856767.2856790\n\n31\n\nACM Classification Keywords\nH.5.m.",
        "Information Interfaces and Presentation (e.g.",
        "HCI):\nMiscellaneous\n\nINTRODUCTION\n\nOptical character recognition (OCR) has improved signifi-\ncantly in recent years [27] and is used in various domains,\nfor example to digitize printed documents (e.g.",
        "books) [16],\nto translate text in real time [35] or to provide assistive tech-\nnologies for blind and visually impaired users [3].",
        "However,\nOCR results are still error-prone and heavily depend on the\nquality of both the picture taken and the printed text [11]: the\nhigher the quality of the picture and text, the better the results,\nand inversely.",
        "This makes it hard to achieve reliable OCR re-\nsults in domains that are confronted with e.g.",
        "text fonts that\nare hard to recognize, pale ink, or crumpled paper [37,40] and\ngets even worse when taking pictures with a smartphone cam-\nera because of bad lighting and distortion of the picture [11].",
        "One approach to fix spelling errors is using crowdsourcing\nwhich relies on the concept of the wisdom of crowds [34].",
        "This concept states that a group of people is able to come to\na better decision than an individual [34] and is often used to\novercome problems that cannot adequately be solved by com-\nputers [7,18] or to enhance algorithms by combining meth-\nods from artificial intelligence and crowdsourcing [4].",
        "In this\npaper we investigate a crowd-based approach to enhance the\noutcome of OCR.",
        "Our goal is not solely to correct spelling\nerrors, as done in existing work [1, 6, 12, 26] but also se-\nmantically enhance OCR results and attach meaningful meta-\n\n\nIUI 2016 * Social Media\n\ndata by the use of designated microtasks solved by an unpaid\ncrowd.",
        "We evaluated our approach in the domain of receipt\ncapturing to keep track of expenses with a special focus on ex-\ntracting single articles, corresponding prices and an appropri-\nate categorization.",
        "Existing attempts in this field using rule-\nbased mechanisms [32] or machine learning methods [40]\ndid not provide this information, probably because extracting\nthose entities adds substantial difficulty to the OCR problem\nspace.",
        "The increasing interest in self-tracking [24, 39], and\nthe desire to track expenditures, additionally strengthen the\nneed for a solution to this problem.",
        "We developed a budgeting application (cf.",
        "Figure 1) for\nsmartphones that allows for tracking expenses by taking pic-\ntures of receipts to extract relevant entities such as the to-\ntal sum, store name, single articles and their corresponding\nprices, and a categorization of both the receipt and each arti-\ncle.",
        "To enhance the recognition algorithm, we used the out-\ncome of different microtasks that were solved by users of\nour app.",
        "Solving these microtasks is not motivated by mon-\netary rewards because it may negatively influence the quality\nof the generated solutions [25].",
        "Instead, we use gamifica-\ntion - the use of game elements in non-game contexts [8], as\nit has already been successfully used in the field of crowd-\nsourcing [6, 10,21, 36].",
        "The presented system is able to run\nin a self-sustained manner without using any external crowd-\nsouring platforms.",
        "In a three-week-long user study, we found\nthat the error rate when extracting entities from receipts can\nbe significantly reduced with the help of crowd-solved micro-\ntasks and that the outcomes of these microtasks additionally\nimprove entity extraction in future receipts.",
        "Moreover, we\nwere able to confirm positive effects of the gamification ele-\nments on the willingness of subjects to participate.",
        "The paper is structured as follows: we first review the chal-\nlenges in performing OCR in the receipt analysis domain by\ninspecting German receipts from different stores, and report\nthe results of an online study.",
        "We then consider related work\nand introduce how we integrated the findings into a smart-\nphone prototype.",
        "Finally, we report and discuss the results of\na user study using our prototype.",
        "DOMAIN-SPECIFIC CHALLENGES AND REQUIREMENTS\nTo identify technical challenges, we inspected receipts to\ndraw conclusions about their content and structure.",
        "We fur-\nthermore utilized an online questionnaire and reviewed pop-\nular budgeting applications informally to establish require-\nments for our prototype.",
        "More information about the online\nquestionnaire and the receipt analysis can be found in [20].",
        "Receipts Analysis\n\nOne major problem when extracting entities from receipts au-\ntomatically is the absence of a uniform format [32].",
        "We there-\nfore inspected 117 German receipts from 85 different shops to\ndeduce an abstract model for German receipts.",
        "We analyzed\nall receipts using two reviewers, each one inspecting every\nreceipt, and thereby identified three sections (see Figure 2a):\n\n1.",
        "Header: In 84.7% of all receipts, the store’s name was\nprovided as plain text.",
        "In addition, this region contains in-\nformation about the store’s address (95.3%), its telephone\n\n32\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\n% PRICE\n\nPRICE\n\nMWSt —_ BRUTTO\n\n3\n=\nSom &\nMio a\neSca\n\n( INeTION }} 39x PRICE\n66111 Saarbriicken, Dudweiler Str.",
        "48\nSee i068 s3815523 WW.",
        "NETTO-ONLINE .DE\n2 06.12.13 15x\noR PRICE\nnite FK SU NEES 1,99 B\n-G.Pesto sort.",
        "190g 1,19 B\nBackfee Kokosraspe1n200g 0,45 B PRICE\nBF Oblaten 50mm 1S0er 0498 D| 10x\nBE Cornichons 720m) 0,89 B\nFruchtstHe imFruechDYEWIL 1,09 A\nSUMME [6] 6,10\nBar EUR 10,00\n\nBei Bezahlung mit cardNaore erhalten Sie 8x\n7 Punkt(e)\n\nInformationen unter www.netto-online.de\n\nFEREEES ERE REE EEAEAA AEDES AER SRE SER ES SERRE\n*Stars.Style.Sparen* 3\n\nNeue Ausgabe: gold - Das Star-Magazin.",
        "HREEAEEEESE EEASEREE EEE EEE EAA SEES EES EE EE\n\nVielen Dank fir Ihren Einkauf\nSteuer-Nr .0E133822409\n\n3x\nPRICE\n\nPRICE\nPRICE\n\nUnsere Offnungszeiten\nMontag-Samstag 7:00-20:00 Uhr\n\n1x\n\n774 4070568\n\n19:28\n\nFigure 2: a) A typical receipt from a German supermar-\nket with the identified regions: header (1), body (2), addi-\ntional information (3).",
        "b) Arrangement patterns of arti-\ncles and prices; % denotes additional information\n\nnumber (83.5%), the date of purchase (100%), or the web-\nsite (41%).",
        "We found that the name of the store has no\nconsistent format (since it is of arbitrary length and con-\ntent); nor could be a fixed location identified for the store’s\nname within the header region.",
        "2.",
        "Body: The body contains listed articles together with their\nprices as well as the total sum of the purchase.",
        "Since we\naim for extracting single articles together with correspond-\ning prices, we further examined how prices, article names\nand additional information (like article numbers, quantity,\netc.)",
        "are aligned, and determined seven different patterns\nwithin our sample, as depicted in Figure 2b).",
        "We also ana-\nlyzed the chosen wordings for the total sum of a receipt and\nfound that there are 18 different representations used in our\nsample: most often the German word for “sum” was used\n(39), followed by “total” (31), and 16 remaining words that\nwere distributed with high variance.",
        "3.",
        "Additional information: This section contains entries not\ndirectly necessary for the capturing process.",
        "However, we\nfound that there may be information (e.g.",
        "a web address)\nthat could be helpful if the header is not recognized.",
        "Based on these findings, we deduced four challenges when\nextracting relevant entities from receipts:\n\nC1: Identification and extraction of the store’s name\n\nThe analysis showed that it is hard to identify and extract the\nstore’s name because of its arbitrary length, content and for-\nmat.",
        "Matters were complicated further due to the fact that no\nfixed location could be determined.",
        "C2: Identification of articles and extraction of their prices\nThe layout examination of articles and corresponding prices\nrevealed that it is not possible to simply match prices with\n\n\nIUI 2016 * Social Media\n\nU.096 kg xX 3.99 EUR/kg= q\n4x 0,89\n\nVOLLMILCH 3,8% 3.56 7\nMINI DICKMANNES 1.59 7\n\nFigure 3: Article name (red rectangle on the left) and cor-\nresponding price (red rectangle on the right)\n\nwords of the same line to extract the article name because\nthere is no consistent format or structure given (cf.",
        "Figure 2b).",
        "Moreover, article names are also of arbitrary length, making a\npurely programmatic approach more or less impossible.",
        "Fig-\nure 3 illustrates the problem of matching an article name to\nthe corresponding price.",
        "C3: Categorization of single articles and the whole expense\nWe consider deducing categories for single articles and the\nwhole expense hard, since no information allowing inference\nof a category can be found on the receipt.",
        "C4: Identification and extraction of the total sum\n\nAs our analysis reveals, although there are a lot of receipts\nusing the same wording, which could be used to identify the\ntotal sum in most cases, there is still an incomplete set of\nfurther wordings that need to be considered.",
        "Online Questionnaire\n\nWe setup an online questionnaire to obtain information about\nparticipants shopping behavior, their interest in keeping track\nof expenses, and their attitude towards automatic receipt cap-\nturing to establish requirements for our prototype.",
        "The ques-\ntionnaire was available for six weeks.",
        "Participants\n\nWe recruited 238 participants (Female: 101).",
        "Concern-\ning age, the data is skewed young (<18: 2.73%, 18-25:\n51.26%, 26-30: 13.03%, 31-40: 10.92%, 41-60: 19.33%,\n>60: 2.73%).",
        "This can be explained by the way the question-\nnaire was promoted (social media and student mailing lists).",
        "Results\n\nAlthough 82.35% of the participants were not keeping track\nof their expenses, only 12.18% claimed to be uninterested in\ndoing so.",
        "Asked for causes, participants stated that the main\nreason is the high amount of effort to track expenses manu-\nally (stated by 57.98%).",
        "We therefore conclude that our pro-\ntotype needs to ease the process of tracking expenses (R1).",
        "Participants reported visiting weekly farmer’s markets and\nother specialized markets at least infrequently (5.88%), which\nmakes a manual way to record expenses necessary (R2), since\nthere are not always receipts provided.",
        "We moreover learned\nthat the majority of people who own a smartphone (83.61%)\nalways have it available (70.85%) while shopping or at least\nmost of the time (21.11%).",
        "Additionally, a majority (64.71%)\nof participants stated that for receipt capturing they would\nprefer to take a photo with their smartphone.",
        "These two find-\nings suggest that an application for mobile devices is the most\nsuitable platform for our system (R3).",
        "46.64% of the partici-\npants prefer to categorize the whole purchase instead of single\n\n33\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nitems.",
        "Still, 16.38% would want every single item catego-\nrized, and 27.31% want both (single items and the whole pur-\nchase).",
        "Therefore, both options should be offered (R4).",
        "Con-\ncerning the evaluation period, 82.35% prefer monthly records\nof their purchases, which requires statistics and filters to al-\nlow for monthly aggregation (R5).",
        "Informal Budgeting App Review\n\nAfter establishing requirements based on the online question-\nnaire, we informally reviewed 10 budgeting apps, with a spe-\ncial focus on popular apps as reported in [2], to establish a\ncore set of requirements for our prototype.",
        "We discovered that\nall reviewed apps contained statistics allowing aggregation of\nexpenses at least by month and by category.",
        "Additionally, the\namount of money spent was visualized using different types\nof charts.",
        "We therefore require the prototype to offer the pos-\nsibility to visualize expenses in a statistical manner (R6).",
        "We\nfurthermore learned that there should be a way of seeing all\nexpenses together with the possibility to filter for different\ntime intervals (R7).",
        "Other core functionalities that should be\noffered are editing and deleting expenses (R8).",
        "Based on the\nreview, we additionally identified 10 different categories by\ntaking the most provided categories within the applications\ninto account.",
        "This information was used to build a basis set\nof categories (groceries, electronics, personal hygiene, fash-\nion, household, pet needs, gardening, freetime, other) to be\nused for the categorization of expenses.",
        "RELATED WORK\n\nWe inspected related work in the domain of crowdsourcing\nin general, approaches using crowdsourcing to correct OCR\nresults, and related work in the domain of automatic receipt\ncapturing as these domains are relevant for our work.",
        "Crowdsourcing Picture Classification\n\nThere exist many approaches using crowdsourcing to solve\nproblems that cannot be solved by machines in a simple way.",
        "For example, Von Ahn and Dabbish [36] developed the ESP\nGame, in which randomly paired players see images they\nneed to tag.",
        "Every time they agree on a word, they receive\npoints and the word is accepted as a valid tag.",
        "The approach\nconfirms that a crowd can be used to annotate pictures and\ngenerate meaningful metadata, which is what we also do, but\nin another domain.",
        "Another example showing that a crowd\nnot only succeeds in categorizing entities based on images,\nbut outperforms single users in this task, can be seen in Les-\nsel et al.",
        "[21].",
        "The authors make use of crowdsourcing to\ngenerate classifications of waste that was inserted into an aug-\nmented recycling bin.",
        "Based on these classifications, feed-\nback was provided to both the crowd as well as people stand-\ning in front of the trash bin, thereby educating them towards\nsustainable recycling behavior.",
        "This approach is also interest-\ning for us since the crowd was not paid; instead, users were\nmotivated through game elements, which we also aim for.",
        "Crowdsourcing and OCR\n\nOne prominent approach is the reCAPTCHA system [37],\ndisplaying pictures of words extracted from scanned texts\nto people visiting websites.",
        "The extracted words are those\n\n\nIUI 2016 * Social Media\n\nthat are unrecognizable by OCR.",
        "By typing the correspond-\ning word, users can confirm they are human and indirectly\nfix OCR errors.",
        "The approach showed that a crowd is able\nto correct errors even when the crowd size is low (six users\nare sufficient) and additionally proved that a post-correction\nof OCR errors by human beings increases the accuracy com-\npared to standard OCR.",
        "These findings support our idea of\nusing a crowd to correct errors in extracted entities.",
        "Addi-\ntionally, the fact that the crowd does not need to be large is an\nimportant information for the validation process in our proto-\ntype.",
        "Nevertheless, the reCAPTCHA system is used to cor-\nrect OCR errors without regarding semantic coherences, as\nwe do in order to identify and match articles and prices.",
        "The Australian Newspapers Digitization Project (ANDP) [16]\nfollowed the idea to use OCR corrections to improve their\ndigitized historic newspaper articles.",
        "They created a web ser-\nvice that volunteers could use to correct text passages.",
        "More\nthan 9,000 users corrected over 12.5 million lines of text,\nand the number of volunteers participating in this platform\nis growing further [31].",
        "This approach also shows the suc-\ncess of a crowd correcting erroneous text regions.",
        "However,\nin line with the reCAPTCHA approach, the focus of ANDP\nis not to provide microtasks to gain semantic coherences or to\nuse collected information to improve an extraction algorithm,\nas covered by our work.",
        "Turning crowd-based OCR correction into a game was in-\nvestigated in the Digitalkoot system [6].",
        "The system aimed\nto improve the digitalization of old newspaper articles from\nthe National Library of Finland.",
        "Two games were developed,\nboth based on pictures of words already extracted by an OCR\nengine.",
        "Over 4,768 people were recruited in 51 days, com-\npleting more than 2.5 million tasks by using a gamified and\ncrowd-based approach.",
        "This supports our idea of using a\ncrowd-based approach and gamification as a motivator.",
        "Automatic receipt capturing\n\nConsidering the digitalization of receipts, there are several\nattempts to be found in literature.",
        "One is the work of Zhu et\nal.",
        "[40] which describes an approach for automatic expense\nreimbursement using OCR to digitize receipts with the help\nof conditional random fields and regular expressions.",
        "The lat-\nter were used to extract entities with limited variation, such as\nphone numbers or the transaction amount.",
        "Conditional ran-\ndom fields were used to extract entities having large varia-\ntion (e.g.",
        "store names).",
        "The results show that this system\nis more robust to recognition errors, but still is far from be-\ning accurate, which motivates us to investigate a crowd-based\napproach in this context.",
        "Receipts2Go [19] is another system that also targets the digi-\ntalization of single-sided documents, by capturing them with\na cell phone, which is in line with our idea.",
        "They also used\nregular expressions to extract entities with low variety.",
        "How-\never, there is no evaluation of this concept, and the question\nof how well this approach performs remains open.",
        "The fact\nthat the authors suggest qualifying an image before process-\ning it, post-processing of OCR results and using results from\nextractions in the past to improve OCR results, supports our\nconcept, in which we provide live feedback when capturing\n\n34\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nexpense\n\nexpense =\n\n00 P.\n\n@ You need only 130 points to reach the next\n\n2015 (Yearly view)\n\ncA STATISTICS\n\nEXPENSE OVERVIEW\n\n379,21 €\n\nThis month,\n\n235,p0-e\n\nLast Month\n\nRECENT EXPENSES\n\nRewe\non 10-5:2015\n\n23,00 €\n\n—_\n\n[omen aon nne\n\nFigure 4: a) Main screen and b) statistics view of our app.",
        "a receipt and use crowd-generated content from past extrac-\ntions to infer relevant information for upcoming analysis.",
        "In contrast to our work, both approaches considered only cer-\ntain elements to be extracted: Individual articles together with\ncorresponding prices, and a proper categorization, were not\nconsidered.",
        "Since both approaches used regular expressions\nfor the extraction of entities with low variety, we adapted this\ntechnique in our algorithm.",
        "The work of Shen and Tijerino [32] relies on ontologies to\nextract entities from receipts and uses an Object-Relationship\nModel, which provides information about sets of objects and\ntheir relationship, as well as constraints over object and re-\nlationship sets.",
        "As this approach relies on perfect, flawless\nOCR results, it may not be directly applicable in our set-\nting, in which receipts are captured with a smartphone cam-\nera.",
        "Therefore, we additionally use crowdsourcing to correct\nand classify entities and try to combine information gained\nthrough the crowd with static methods described in this work.",
        "To our knowledge, our approach is the first investigating\ncrowdsourcing to reduce the error rate when extracting rele-\nvant entities for expense tracking.",
        "Using gamification to mo-\ntivate the crowd enables our system to run in a self-sustained\nmanner and furthermore allows to investigate the effects and\nthe perception of gamification in this domain.",
        "This is impor-\ntant since there exists work demonstrating that gamification\nis not always successful [14] and depends on many different\nfactors [38].",
        "To our knowledge, there seems to be no other\nwork considering the identification and extraction of single\narticles together with respective prices and categories based\non a photographed receipt.",
        "In contrast to existing approaches\nmaking use of crowdsourcing only to correct text errors, we\ngo a step further and use microtasks to obtain semantically\nrelevant information to enhance our recognition algorithm.",
        "SYSTEM DESIGN\n\nTo evaluate our approach, we developed a budgeting appli-\ncation that allows for tracking expenses by taking pictures of\nreceipts.",
        "The design of this prototype is based on the require-\nments we have established, and implements solutions to the\naforementioned challenges.",
        "To enhance the recognition algo-\nrithm, we used the outcome of different gamified microtasks\nthat were solved by an unpaid crowd.",
        "IUI 2016 * Social Media\n\nConcept\n\nWe designed the concept of our prototype based on the results\npresented in the last sections.",
        "To accomplish R3, we decided\nto target mobile devices and implemented our prototype as an\nAndroid application.",
        "This also seems to be beneficial regard-\ning the ease of tracking expenses (cf.",
        "R1) since it offers the\npossibility to add expenses by taking pictures of receipts with\nthe smartphone’s camera.",
        "During the conceptualization we\nalso performed a usability test as suggested by Nielsen [29]\nwith 5 participants (3 female), aged 33 on average.",
        "We asked\nthem to accomplish tasks within the app and used a think-\naloud approach [28].",
        "Participants were also asked to solve 25\nmicrotasks including all task types.",
        "Impacts of the usability\ntest on our concept are stated in the following sections.",
        "Budgeting Features\n\nOn the home screen of our application (cf.",
        "Figure 4a) we show\nthe overall amount of money spent in the current month as\nwell as in the last month (cf.",
        "R5).",
        "Clicking on the monthly ex-\npenses directly takes the user to a view showing all expenses\nfrom the corresponding month, as this functionality was con-\nsidered important in the usability study.",
        "Furthermore, the last\nexpenses were shown together with categories, total sum, and\nthe store name.",
        "The prototype furthermore provides a view\nin which expenses are visualized in a statistical manner (cf.",
        "Figure 4b) based on categories of single articles or the cat-\negory of the overall expense, which can be set by the user\n(cf.",
        "R4, R6), and custom time intervals (cf.",
        "R7).",
        "Moreover,\nthe app can show all expenses and filter them by year or by\nmonth (cf.",
        "R7, R5).",
        "Expenses can always be edited or deleted\n(cf.",
        "R8) and may also be added manually (cf.",
        "R2).",
        "Automated Receipt Capturing\n\nThe workflow (cf.",
        "Figure 1) of adding expenses by taking a\npicture of the receipt starts before the user actually takes the\nphoto.",
        "As suggested in several related works [11, 19], live\nfeedback on the quality of the picture is given (cf.",
        "Figure 5c\nand Figure 5d) in form of a smiley in the camera view to en-\nhance the OCR outcome.",
        "As soon as a picture is taken, it\ngets preprocessed and text is extracted by an OCR engine on\nthe user’s smartphone.",
        "We decided to outsource the whole\nextraction to the user’s smartphone to keep the traffic as low\nas possible for the user and reduce the workload on the web-\nserver, to which the result containing recognized text and cor-\nresponding line numbers is sent.",
        "On the webserver, we extract\nall relevant information based on the received OCR result us-\ning the outcomes of microtasks solved by the crowd.",
        "In the following sections we describe in more detail how we\nrealized the concept.",
        "Receipt Capturing and Image Preprocessing\n\nAs the quality of the picture taken greatly affects the quality\nof the OCR result [11], we decided to implement different ap-\nproaches to enhance the picture taken by the user.",
        "In a first\nstep, we provided live feedback on the quality of the picture\nin form of a smiley in the camera view.",
        "Whether the smi-\nley is green and smiling (cf.",
        "Figure 5c) or red and frowning\n(cf.",
        "Figure 5b) depends on lighting and the orientation of the\nmobile device, since both attributes have been identified as\ncrucial for good OCR results in the literature [11,15].",
        "35\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nFigure 5: a) Identified horizontally aligned regions, b) Un-\nfavorable position of the camera, c) Suitable picture, d)\nRegion Of Interest (ROD\n\nTo measure whether there is too much distortion or the image\nis skewed, we implemented an algorithm that identifies hor-\nizontally aligned regions on the given picture by using edge\ndetection methods together with morphological closing trans-\nformations.",
        "In a further step, we calculate bounding boxes for\nthese regions, as shown in Figure 5a).",
        "If the boxes are higher\nthan they are wide, we can conclude that the smartphone is\nin an unfavorable position and distortion might be too high,\nsince we considered words to be wider than high.",
        "Based on\nour receipt analysis, we can also conclude that there is too\nmuch noise in the image (e.g.",
        "because of other text elements\nin the background) when the x-coordinates of the bounding\nboxes are too heterogeneous, since we found that articles on\nreceipts are always in alignment.",
        "After the picture was taken,\nwe preprocessed the picture, since this further enhances OCR\nresults [12]: In a first step we again used the algorithm de-\nscribed above to identify horizontally aligned regions.",
        "Based\non these regions, we identified the region of interest (ROD,\ni.e.",
        "where the receipt is located in the picture.",
        "This was\ndone by discarding all horizontally aligned regions where the\nx-coordinate of the corresponding bounding box was either\nlower than the calculated mean of all x-coordinates, or higher\n(with a certain threshold).",
        "The remaining regions were con-\nsolidated to form another bounding box which represents the\nregion where the receipt is located (represented by the red line\nin Figure 5d).",
        "This area was extracted from the picture to ob-\ntain better results when thresholding it.",
        "Afterwards, we used\nsimilar approaches (thresholding, Gaussian blur, deskewing)\nas reported in related work [15, 19].",
        "Entity Extraction And Consideration Of Posed Challenges\nAfter preprocessing we used tesseract!",
        "to extract text regions\nfrom the picture on the user’s smartphone.",
        "The extracted text\nis uploaded to a webserver, where three steps to extract all\nrelevant entities from the receipt are performed:\n\n1: Receipt Segmentation\n\nAt first, we divide the receipt into three regions: header, body\nand additional information (cf.",
        "Figure 2a).",
        "To identify the\nheader, we search for the first occurrence of a price, using\nregular expressions.",
        "Once a price is found, the line above is\nconsidered to represent the end of the head section.",
        "After-\nwards, we search for words indicating the total sum in our\n\nIhttps://github.com/tesseract-ocr, last accessed January\n5, 2016\n\n\nIUI 2016 * Social Media\n\na expense =b\n\nont) Sait\n\nHaribo Goldbaeren 360g\n\n‘expense = Cc expense =\n\nMilka Schokol.sort.",
        "100g 0,69 8 1,03 B\n\nWhat is depicted in the image?",
        "Please name the depicted article!",
        "Please categorize the depicted\n\narticle!",
        "Article\nGroceries\n\n18 tasks remaining ;\n18 tasks remaining\n\nqa 20 tasks remaining\n\nFigure 6: Crowd microtasks: a) Classification, b) Article\nnaming, c) Article categorization.",
        "database, that were collected by solving microtasks, to find\nthe end of the body region.",
        "Once we find such a word, we as-\nsume the respective line to contain the total price, which can\nbe extracted using regular expressions, targeting C4.",
        "More-\nover the line containing the total sum represents the end of\nthe body region.",
        "The remaining part of the receipt is there-\nfore considered to be the additional information region.",
        "2: Extracting the Store's Name\n\nAfter dividing the receipt in the three parts, we assume to find\nthe store’s name in the header region.",
        "Moreover, as our anal-\nysis revealed, the header may contain entities like the store’s\naddress, its URL and the phone number, which serve as store\nidentifiers and can be determined using regular expressions.",
        "Once store identifiers are extracted, they can be looked up\nin the database to find a matching store and thereby over-\ncome Cl.",
        "Every time a user corrects an extracted store in\nthe app, we save the correction in our database and link it to\ncorresponding store identifiers, which allows to deduce the\ncorrect merchant in future analysis.",
        "3: Extracting Article Names and Corresponding Prices\n\nAs we learned by the receipts analysis, article names and\ntheir prices can be found in the body.",
        "Therefore, we iden-\ntify all prices within the body region, using regular expres-\nsions.",
        "Next, we iterate over all lines in the body and perform\na fulltext search as well as use Levenshteins distance [23] to\nfind the content of this line in our database, which contains\nthe outcome of all crowd-solved microtasks.",
        "We search in\nthe table containing the corrected versions of entities but also\nin the table containing the raw, possibly erroneous OCR ver-\nsion of entities to compensate for spelling errors.",
        "Once we\nfind a match, a classification (article, additional information)\nfor this line can be made, based on the outcome of the as-\nsociated classification microtask (cf.",
        "Figure 6a).",
        "Using these\nclassifications, we can match one of the patterns we found in\nthe receipts analysis (cf.",
        "Figure 2b), which allows to infer a\nmatch for an article and the corresponding price solving C2.",
        "Once a line is classified as an article, we can also receive its\ncorrected name by the outcome of the respective article cor-\nrection microtask (cf.",
        "Figure 6b) and its corresponding cate-\ngory through the result of the article categorization microtask\n(cf.",
        "Figure 6c) and thereby also provide a solution for C3.",
        "Crowd Microtasks\n\nWhenever a line cannot be classified properly, i.e.",
        "the entity\ncannot be found in our database, a microtask is generated to\nobtain missing information.",
        "36\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nWe decided to divide all problems or unknown entities of a re-\nceipt into microtasks, instead of creating larger tasks like cor-\nrecting and classifying a whole receipt at once.",
        "This strategy\nis considered to lead to fewer mistakes, a greater stability in\nthe face of interruption, and provides an easier experience for\nthe user [5].",
        "In the app, each microtask is shown isolated and\nconsist of an image of the unknown receipt line and a short\ntask description, following the suggestions given for crowd\nuser interfaces in [30].",
        "Users can decide to either solve own\ntasks, which means that these tasks correspond to problems\nthat occurred when analyzing own receipts, or crowd tasks\nthat were generated when analyzing receipts of other users.",
        "Every microtask can be skipped by the user, because the con-\ntained picture may be of low quality or ambiguous in some\ncases (e.g.",
        "if more than one line was extracted accidentally).",
        "If a microtask is skipped by at least six users, we discard the\npicture, similar to [37], as it cannot be used to infer proper in-\nformation.",
        "However, the owner still can manually update the\nreceipt and thereby provide a solution for the respective mi-\ncrotask.",
        "We decided to use three different task types, which\nwe assume to be helpful to match articles and prices, to ex-\ntract the total sum, and to categorize articles and the overall\nexpense (cf.",
        "Figure 6):\n\nClassification Microtasks\n\nBased on the receipt analysis we identified three different\ntypes for entities: article names, additional information\n(e.g.",
        "article numbers or quantity indications) and total sum.",
        "Given the classification of a line (whether it contains an ar-\nticle, additional information or a total sum), we are able to\nmatch articles and prices and furthermore extract an overall\nsum for the purchase.",
        "Therefore, this task is the first task that\nis generated when an entity cannot be classified.",
        "The user is\nasked to identify the entity to be an article, additional infor-\nmation or total sum, as depicted in Figure 6a).",
        "In the usabil-\nity test, participants had no problems classifying entities as\narticles or total sums but struggled to classify entities as addi-\ntional information.",
        "As a reason, they stated that the wording\nseemed too generic for them.",
        "We therefore added more spe-\ncific classification options that are internally mapped to the\nadditional information option.",
        "Article Correction Microtasks\n\nThis microtask is created once an unknown entity is identified\nas an article by the crowd.",
        "The user is asked to name a de-\npicted article as shown in Figure 6b).",
        "The outcome of this mi-\ncrotask is used to correct OCR errors (spelling errors), iden-\ntify and distinguish articles and provide a meaningful article\nname, since the articles are often abbreviated on the receipt.",
        "This task also makes it possible to store a relation between the\nraw text obtained by the OCR engine and the corrected ver-\nsion.",
        "This relation is very useful since it can compensate for\ntypical OCR errors (e.g.",
        "confusing a zero with the letter “O”\nor spelling errors) and makes it possible to match abbreviated\narticle names to their corrected versions.",
        "Article Categorization Microtasks\nAgain, this microtask is generated after an entity was clas-\nsified as an article, to obtain a meaningful category for it.",
        "IUI 2016 * Social Media\n\nexpense expense\n\n* 40 |\n\n@ You need only 40 p\nrank\n\nTask finished\n\n*+10P unlocked!",
        "Own (1)\n\nMilka Schokol.sort.",
        "100g 0,69 B\n\nEXPENSE (\nWhat is depicted in the image?",
        "(1)\n\n%* +50 P.\n\nSES)\n\nThis month\n\n285,38 €\n\nLast Month\n\nArticle .",
        "Solve Task!",
        "18 tasks remaining\n\nAchievement\n\nReceipts-Collector\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nexpense expense\n\nReceipt Master # HIGHSCORE\n\n# 300 points :\n\nName Points\n\n¥ Achievements\n\n@@.",
        "Crowd- Task-\n\nTerminator 28380\n\nShow profile\n\nCrowd- Shoppingqueen\n\n26240\n\nSpecialist Leader Assistant Show profile\nLevel 0 Level 0 Level 0\nRechnungsexperte\nShow profile\nTask- Task- Receipts-\nSpecialist Master Collector Rechnungssammler\n\n16350\n\nLevel 0 Level 0 Level 1\n\nShow profile\n\nFigure 7: Different game elements used in the prototype.",
        "a) Points are awarded.",
        "b) An achievement is unlocked.",
        "c)\n\nPersonal profile.",
        "d) Leaderboard.",
        "The user can decide between ten different categories (cf.",
        "Fig-\nure 6c) we established in the budgeting apps reviewing pro-\ncess.",
        "The categorizations provided by this task are used not\nonly for single articles but also to categorize a whole expense\nbased on the categorizations of each purchased article, as this\nis required by users (cf.",
        "R7).",
        "Solving Microtasks\n\nAs soon as a minimum amount of users (in our prototype we\nrequired at least six participants since [37] indicates that this\namount is sufficient) participated in a microtask, a solution is\ngenerated for this task.",
        "Depending on the type of the task, the\nmethod to acquire this solution differs.",
        "A classification needs\nto reach at least least 60% of all votes.",
        "Once this is achieved,\nthe raw OCR result gets stored in our database, together with\nthe determined classification.",
        "This allows to recognize simi-\nlar entities in the future, provide input for the entity extraction\nalgorithm, and thus decrease the amount of errors.",
        "Once an\nentity is voted to be an article, both Article Correction and\nArticle Categorization Microtasks are delegated to the crowd.",
        "The outcome of these tasks are determined by selecting the\noption with the most votes.",
        "Once an option is chosen, the\ncorresponding article name gets corrected or respectively gets\nenriched by a category.",
        "The owner of the associated receipt\ngets notified about all changes and corrections that were per-\nformed by the crowd (cf.",
        "Figure le).",
        "The textual representa-\ntions of these changes were significantly shortened after par-\nticipants considered them as too long in the usability test.",
        "Gamification Elements\n\nTo motivate users to solve microtasks and use our app, we in-\ntegrated different gamification elements and thereby followed\nthe design implications given in [33], stating that a budgeting\napp should use methods to engage users so that they keep\ntracking expenses over longer timescales.",
        "Gamification has\nbeen successfully used in many crowdsourcing systems to\nmotivate and engage users [21,37].",
        "Furthermore, the use of\ngamification was able to improve crowd participation and the\nnumber of solved tasks in different domains [13].",
        "We decided\nto integrate points, badges and a leaderboard together with a\npersonal profile to provide attributes to measure fame or rep-\nutation, which is considered to motivate and retain users [9].",
        "Points (cf.",
        "Figure 7a) can be collected by solving microtasks\n\n37\n\nor receiving badges.",
        "A badge is awarded if the user solves\nan extraordinary amount of microtasks or regularly uses the\napp (e.g.",
        "by scanning receipts; an example is depicted in Fig-\nure 7b).",
        "However, we did not want to give points without\nany meaning, but instead decided to grant users advantages\nbased on their score.",
        "Since solving microtasks is a service\nof one user for a whole crowd, we wanted to make sure that\nmicrotasks of users working a lot for the crowd are delegated\nwith higher priority than those of users not solving many mi-\ncrotasks to other users.",
        "This means that problems that occur\nwhen analyzing a receipt of a user who solves many micro-\ntasks of the crowd are delegated and potentially solved faster\nthan problems of users solving few microtasks for others.",
        "Ad-\nditionally, we integrated a leaderboard (cf.",
        "Figure 7d) since\ncompetition is perceived as positive and motivating by many\nusers [25] and is considered a solid retention scheme [9].",
        "To\nfurther motivate users, we also showed their current rank and\nhow many points are needed to get to the next rank directly\non the home screen of our app.",
        "Unlocked badges, the amount\nof points and the username were summarized in a personal\nprofile (cf.",
        "Figure 7c).",
        "Users could also see in their profile\nwhat they need to do to receive a certain badge and how their\npoints, their rank on the leaderboard and the priorization of\ntheir problems are related to each other.",
        "EVALUATION\nBy the evaluation of our approach, we tried to find evidence\nfor the following hypotheses:\n\nH1 Our prototype subjectively eases keeping track of ex-\npenses.",
        "H2 The outcome of designated microtasks solved by a crowd\ncan be used to reduce the error rate of captured receipts.",
        "H3 The outcome of microtasks solved by a crowd can be\nused to reduce the error rate of new receipts that are un-\nknown to the system.",
        "H4 Gamification motivates users to solve microtasks.",
        "H1 is motivated by findings from our online study suggesting\nthat users are interested in keeping track of expenses but shy\naway from the huge effort involved.",
        "Since our system allows\ncapturing receipts by photographing them, we assume that we\nease the capture of expenses.",
        "H2 builds on the assumption\n\n\nIUI 2016 * Social Media\n\nthat our approach using the outcomes of crowd-solved micro-\ntasks lowers the error rate, compared to a baseline without\nany crowd-based data, when extracting relevant information\nfrom captured receipts.",
        "H3 is based on the assumption that\nsolving a certain microtask not only affects a single receipt,\nbut helps to improve other receipts to be captured in the fu-\nture as well.",
        "If we can show that our approach works, i.e.",
        "that\na crowd solving microtasks indeed leads to a lower error rate\nwhen extracting entities from receipts, the question remains\nopen how to motivate a crowd to solve microtasks without us-\ning monetary incentives.",
        "This leads to H4 which is motivated\nby the related work [6, 13,21, 36] showing that gamification\nhas positive effects in crowdsourcing.",
        "Method\n\nWe let participants use our prototype for three weeks and\nasked them to capture their expenses.",
        "At the beginning of the\nstudy, the app was locked and automatically generated a pass-\nword.",
        "This password needed to be used to fill out an online\nquestionnaire assessing buying behavior as well as interest in\nand experiences with tracking expenses.",
        "Only after finishing\nthis questionnaire was the app unlocked.",
        "To investigate H4, gamification elements were not visible in\nthe first week, so as to acquire a baseline.",
        "We decided against\na counterbalanced measures design (i.e.",
        "reversing the order\nof half the participants) since deactivating game elements\nlater could have detrimental effects on participants [14].",
        "Af-\nter the first week, the app was automatically locked again\nand could be unlocked by finishing the mid-session online\nquestionnaire.",
        "In this questionnaire we provided questions\nabout the app usage, how tracking expenses was perceived\nby the participants, how motivated they were towards solv-\ning microtasks, and what could be done to increase their\nmotivation.",
        "After this questionnaire was finished, the app\nwas unlocked again and all gamification elements activated.",
        "Two weeks later, participants were asked to take part in\nthe post-session questionnaire, which had similar questions\nas the mid-questionnaire for purposes of comparison.",
        "We\nasked questions about how tracking expenses was perceived\nand whether participants were motivated to solve microtasks.",
        "Furthermore, we investigated whether certain game elements\nwere considered motivational or not, and provided questions\nrelated to how far our system eases keeping track of expenses.",
        "Both the mid-session as well as the post-session question-\nnaire, were used to investigate H1 by posing questions about\nhow the approach was perceived subjectively concerning ease\nof expense tracking.",
        "We used 5-point Likert scales to mea-\nsure agreement with statements participants were shown to.",
        "During the study, we logged all receipts that were added by\nthe participants together with all solved microtasks to inves-\ntigate H2 and H3.",
        "In order to calculate an error rate, we\nneeded to provide a ground truth for comparison with results\nof our approach.",
        "Therefore, we went through all receipts and\nclassified, categorized and corrected all lines of these receipts\nmanually.",
        "This was done in two steps: One person provided\na ground truth for each line of every receipt that was added\nby the participants and the other one checked for errors (e.g.",
        "spelling mistakes or other interpretation options).",
        "38\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nwo w\nNy WwW\n\nSe\n\nAverage error-rate in %\nNY N N NN W W\nui n VN CO © OC fF\n\nN\na\n\n15 30 45 60 75 90 105 120 135 150\n\nSubsample size\n\n@ CROWD ENHANCED @® PARTICIPANTS EXCLUSIVE @ BASELINE\n\nFigure 8: The error rate of new receipts for the CE al-\ngorithm (green) and the CEPE algorithm (orange) com-\npared with the baseline algorithm (gray) for different sub-\nsample sizes.",
        "Results\n\nIn three weeks, 191 receipts were added by 12 participants (5\nfemale, 7 male).",
        "The age distribution was skewed young (21-\n30: 9, 31-40: 1, >40: 2).",
        "On average, participants added\n15.92 receipts during the study (SD=14.35, Mdn=8).",
        "Be-\nfore the study, only 3 subjects were keeping track of their\nexpenses although 10 participants claimed to be interested in\ndoing so.",
        "Three-fourths of the participants go shopping 3-\n4 times a week, one-eighth go shopping twice a week and\none-eighth claimed to go shopping 5-6 times per week.",
        "Con-\ncerning their buying behavior, participants visit same stores\n(M=4.42, SD=0.52, Mdn=4) and tend to buy the same prod-\nucts (M=4.33, SD=0.49, Mdn=4).",
        "Perception of the Prototype\n\nParticipants stated in the post-session questionnaire that the\napp eases tracking expenses (M=3.91, SD=1.04, Mdn=4)\nand that they would rather use our system than manually\ntrack their expenses (M=4, SD=1.18, Mdn=4).",
        "Moreover,\nthey considered capturing expenses by taking pictures of re-\nceipts to be easy (M=4.45, SD=0.68, Mdn=5) and perceived\nthe smiley as helpful for taking a good picture (M=4.27,\nSD=1.35, Mdn=5).",
        "These findings provide evidence support-\ning H1: the prototype eases keeping track of expenses.",
        "More-\nover, crowd corrections were perceived positively (M=4.38,\nSD=0.74, Mdn=4.5) and considered meaningful (M=4.5,\nSD=0.54, Mdn=4.5).",
        "Participants also had the feeling that\nthey used the app often (M=3.73, SD=1.35, Mdn=4).",
        "Entity Extraction and Crowd Performance\n\nDuring the evaluation, 15393 microtask solutions were gener-\nated by 12 participants, 1282.75 solutions per participant on\naverage (SD=1053.54, Mdn=1101).",
        "To obtain an error ratio\nfor each receipt, we analyzed every captured receipt again,\nusing the outcome of all microtasks (classifications and cor-\nrections) solved by the crowd (crowd-enhanced algorithm,\nCE), and compared the result with an approach that solely\n\n\nIUI 2016 * Social Media\n\nrelies on assumptions concluded by the receipt analysis with-\nout considering the crowd (baseline algorithm).",
        "Since it is\nimpossible to deduce categories of articles for the baseline\nalgorithm (that does not utilize any crowd data), we excluded\nthe category in the error rate to obtain comparable results.",
        "Thus, the error rate is calculated by the ratio of the amount of\nwrong entities (wrong classification and/or wrong value of a\nline) to the overall amount of entities (right classification of a\nreceipt line and correct value).",
        "The baseline algorithm produced an error rate of 31.8%\n(SD=22.02, Mdn=32%) whereas the CE algorithm reached\nan error rate of only 10.36% (SD=14.68, Mdn=5).",
        "A paired\nt-test showed a significant effect between these error rates\n(t(190)=12.47, p<0.01) supporting evidence for H2: the out-\ncome of designated microtasks solved by a crowd can be used\nto reduce the error rate of captured receipts.",
        "To evaluate whether microtasks of one receipt can be used\nto enhance newly added receipts, we picked a random sub-\nsample with 15 to 150 receipts (10 iterations, increasing the\nsubsample size by 15 each time) and used this as a training\nsample.",
        "We then iterated over all receipts that were not con-\ntained in this subsample (the test sample) and applied both the\ncrowd-enhanced algorithm as well as the baseline algorithm.",
        "In the CE algorithm, we only considered solutions of micro-\ntasks that were related to unknown entities of receipts within\nthe selected training sample to enhance receipts in the test\nsample.",
        "Since participants subjectively claimed to buy the\nsame products, we additionally performed a crowd-enhanced\nparticipants exclusive (CEPE) algorithm in which we used re-\nceipts of one user for the test set and the receipts of all other\nusers as training sample to avoid having receipts of the same\nuser in the test set and in the training sample.",
        "To receive\nmore reliable results, we repeated the subsample selection 50\ntimes for each sample size.",
        "Figure 8 shows the error rates\nfor each subsample for all three algorithms.",
        "The results sup-\nport H3: the outcome of microtasks solved by a crowd can\nbe used to reduce the error rate of new receipts that are un-\nknown to the system, since both the CE and the CEPE algo-\nrithm outperform the baseline algorithm in all sample sizes.",
        "We conducted a repeated measurements ANOVA and found\na significant effect between the algorithms (p<0.05).",
        "Pair-\nwise comparisons using the Bonferroni method revealed that\nthe difference between the CE algorithm and the baseline is\nsignificant (p<0.01), as well as the difference between the\nCEPE algorithm and the baseline (p<0.01).",
        "Moreover, the\nCE algorithm performed significantly better than the CEPE\nalgorithm (p<0.01).",
        "The fact that the error rate is decreasing\nwith increasing number of receipts further suggests that our\napproach improves over time (with increasing data retrieved\nby the outcome of microtasks).",
        "Effects and Perception of Gamification\n\nTo obtain insight about how game elements were perceived\nsubjectively by participants, we asked questions concerning\nfun and engagement in the mid- and post-session question-\nnaire and compared answers before and after game elements\nwere active in the app.",
        "Additionally, all used game ele-\nments were specifically addressed in the post-session ques-\n\n39\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nQuestion Mid-Session | Post-Session | sig.",
        "a: Solved many | M=3.58, M=3.67, p=0.723\nown tasks SD=1.44, SD=1.56,\nMdn=4 Mdn=4\nb: Solved many | M=4.17, M=4.17, p=1.0\ncrowd tasks SD=0.93, SD=1.34,\nMdn=4.5 Mdn=5\ne: Solving own | M=2.58, M=4.17, p=0.131\ntasks was fun SD=1.31, SD=1.34,\nMdn=2.5 Mdn=5\nd: Solving crowd | M=2.58, M=3.42, t(11)=2.49,\ntasks was fun SD=1.31, SD=1.51, p<0.05\nMdn=2.5 Mdn=3.5\n\nTable 1: Questions and respective answers concerning fun\nand engagement in the mid- and post-session online ques-\ntionnaire.",
        "Week | Week 2 Week 3 sig.",
        "M=238.25, M=569.75, M=474.75, p<0.05\nSD=209.87, SD=462.05, SD=426.67,\n\nMdn=173.5, Mdn=522, Mdn=415.5,\n\nMin=27, Min=0, Min=0,\n\nMax=676 Max=1258 Max=1169\n\nTable 2: Overview of solved tasks per user/week.",
        "tionnaire.",
        "In the mid-session questionnaire, participants sub-\njectively had the feeling that they solved many of their own\n(cf.",
        "Table 1a) and many crowd microtasks (cf.",
        "Table 1b).",
        "In\nthe post-session questionnaire the feeling of solving many of\ntheir own tasks did not change signifantly.",
        "The same was true\nfor the feeling of having solved many crowd tasks.",
        "However,\nparticipants tended to disagree with the statement that solv-\ning their own microtasks was fun or engaging (cf.",
        "Table Ic),\nas well as solving crowd tasks (cf.",
        "Table 1d) in the mid-\nsession questionnaire (before gamification was active).",
        "In\nthe post-questionnaire for their own tasks, this perception did\nnot change significantly, but improved for crowd tasks sig-\nnificantly (cf.",
        "Table 1d), suggesting gamification had an ef-\nfect.",
        "Concerning the game elements used, the highscore was\nconsidered most motivating (M=3.75, SD=1.56, Mdn=4.5),\nfollowed by points (M=3.67, SD=1.50, Mdn=4) and badges\n(M=3.42, SD=1.31, Mdn=3.5).",
        "Considering the amount of solved tasks per user in each week,\nwe performed a repeated measurements ANOVA and found a\nsignificant effect between the three weeks (cf.",
        "Table 2).",
        "Pair-\nwise comparisons using the Bonferroni method showed that\nthe difference between weeks | and 2 is significant (p<0.05)\nas well as the difference between weeks | and 3 (p<0.05),\nwhereby week | was the baseline phase without any gamifi-\ncation elements.",
        "These results show evidence for H4: the use\nof gamification additionally motivates users to solve micro-\ntasks.",
        "However, the differences between the number of solved\nmicrotasks for each participant in every week (cf.",
        "Figure 9)\nand the ordinary perception of gamification, indicate that al-\nthough gamification overall lead to a higher number of solved\nmicrotasks, there seems to be differences in how gamification\nis perceived and considered motivating.",
        "Figure 9 indicates\nthat some participants were not affected by gamification at\nall.",
        "It also shows that the number of solved tasks decreases\n\n\nIUI 2016 * Social Media\n\n1400\n1200\n1000\n\n8\n\n6\n4\n1 2 3 4 5 6 7 8 9 10 11 12\n\nParticipants\n WEEK2 @WEEK3\n\nNumber of solved tasks\n° ° co}\nao oO oO\n\nfs}\noO\n\n© WEEK 1\n\nFigure 9: Solved microtasks for each participant/week.",
        "for many participants in the last week again.",
        "Although this\neffect was not significant, it poses the question in how far the\nused game elements are able to motivate users in the long run.",
        "Discussion\n\nThe study showed that participants are interested in keep-\ning track of expenses and appreciate an automated approach\nto capture receipts.",
        "Our prototype was considered to ease\nthe tracking process of expenses, supporting H1, and thereby\nmitigating the main reason for not keeping track of expenses:\nthe high effort involved.",
        "The conducted analysis to measure\nthe error ratio of receipts revealed that the crowd-based ap-\nproach is able to significantly enhance the extraction of rele-\nvant information, as it produces roughly only a third as many\nerrors as the baseline approach, showing evidence for H2.",
        "The examination of how far the outcome of microtasks solved\nby the crowd can be used to reduce the error rate of new\nreceipts that are unknown to the system, revealed evidence\nfor H3 since the error rate of both the CE and the CEPE al-\ngorithm performed better than the baseline approach for all\ntraining samples.",
        "However, the differences to the baseline\nare not very high, which most probably is explainable by the\nrelatively low size of the crowd (12 participants) and the lim-\nited time of our study (3 weeks) leading to a relatively low\namount of data.",
        "Further investigation is needed to find out in\nhow far the error rate of new, unknown receipts keeps on de-\ncreasing with increasing crowd size and duration of the study.",
        "An explanation why newly added, system unknown receipts\ncan be enhanced, lies in the increasing amount of collected\ndata which raises the chance of finding receipt entities in the\ndatabase.",
        "The reason why the CE approach performs better\nthan the CEPE approach might be because of the fact that par-\nticipants tend to buy the same articles and visit same stores\n(as they have reported), which increases the chance to have\nsame articles in the test and in the training set.",
        "This, on the\nother hand, is beneficial for an approach as done by us, since\na user that is solving her own tasks can thereby improve the\nalgorithm to better recognize her products in the future.",
        "The\nnumber of solved microtasks was significantly influenced by\nthe use of gamification: It increased dramatically in the sec-\nond week after gamification was introduced and subjectively,\nsolving crowd-tasks appeared to be more fun.",
        "However, we\nalso found that the number of solved microtasks got lower in\n\n40\n\nMarch 7-10, 2016, Sonoma, CA, USA\n\nthe last week of the investigation, but still was significantly\nhigher than in week one.",
        "These results show supporting evi-\ndence for H4.",
        "Nonetheless, as we only investigated the pro-\ntotype short-term, it is questionable whether this is only a\nnovelty effect.",
        "Moreover, the high variance of solved tasks\nper user suggests that the gamification elements are not mo-\ntivating for all users.",
        "An explanation for this can be found\nin [17] showing that competition, as was used in our system,\ncan also be demotivating.",
        "Figure 9 also shows that two partic-\nipants were not interested in solving microtasks, independent\nof whether gamification was active or not, thus necessitating\nfurther incentive mechanisms.",
        "Again, a long-term study with\nmore participants seems suitable to explore the impacts of\ngamification on motivation further.",
        "A larger amount of par-\nticipants also allows to have a control group without any game\nelements throughout the study.",
        "We decided against a control\ngroup in this work as we wanted to investigate whether the\nnumber of solved microtasks increases with gamification for\neach subject, which demands a within-subject design, espe-\ncially considering our low participant count.",
        "CONCLUSION\n\nIn this paper we investigated a crowd-based approach to en-\nhance the outcome of optical character recognition in the do-\nmain of receipt capturing to keep track of expenses.",
        "We de-\nveloped a prototype which made it possible to track expenses\nby taking photos of receipts and not only recognizes enti-\nties, but also enhances them with semantic information.",
        "At\nthe same time the presented system does not rely on exter-\nnal crowdsourcing platforms (e.g.",
        "Amazon Mechanical Turk)\nbut is able to run in a self-sustained manner without using\nmonetary incentives.",
        "We based our approach on an online\nquestionnaire to gain information about participants shop-\nping behavior, their interest in keeping track of expenses and\ntheir attitude towards automatic receipt capturing, as well as\non a receipt analysis to obtain insights about technical chal-\nlenges in this field.",
        "In a three-week-long user study, we were\nable to show that our approach was appreciated by the users\nand eases keeping track of expenses subjectively.",
        "This miti-\ngates the main reason for not keeping track of expenses: the\nhigh effort involved.",
        "We furthermore were able to show that\nour approach significantly reduces the error rate for captured\nreceipts, and that the outcome of crowd-solved microtasks\ncan be used to enhance recognition for new receipts as well.",
        "Moreover, we found evidence that gamification provided ad-\nditional motivation to users to contribute more, solve a higher\namount of microtasks and thereby enrich the database.",
        "In future work we plan to investigate the long-term effects of\nour approach to test in how far the error-rate further decreases\nwhen accumulating more data and whether gamfication can\nbe used to keep users engaged over a longer timespan.",
        "There-\nfore we aim to conduct an in-the-wild study and release the\napp in the market.",
        "Before, we plan to revise our gamification\nconcept in order to motivate a broader range of users and in-\nvestigate how we can change the design and concept of the\nmicrotasks to be more fun and engaging.",
        "One promising ap-\nproach to accomplish this is described in [22], in which users\nare able to decide about the game elements they want to use,\nthus leading to a more tailored gamification design.",
        "IUI 2016 * Social Media\n\nREFERENCES\n\n1.",
        "10.",
        "Hend Al-Rouqi and Hend S. Al-Khalifa.",
        "2014.",
        "Making\nArabic PDF Books Accessible Using Gamification.",
        "Proceedings of the 11th Web for All Conference.",
        "ACM,\n2014.",
        "(2014), 1-4.",
        "DOT:\n\nhttp: //dx.doi.org/10.1145/2596695.2596712\n\n.",
        "Matthias Bohmer, Brent Hecht, Johannes Schéning,\n\nAntonio Kriiger, and Gernot Bauer.",
        "2011.",
        "Falling\nAsleep with Angry Birds, Facebook and Kindle: A\nLarge Scale Study on Mobile Application Usage.",
        "Proceedings of the 13th International Conference on\nHuman Computer Interaction with Mobile Devices and\nServices.",
        "ACM, 20/1.",
        "(2011), 47.",
        "DOT:\n\nhttp: //dx.doi.org/10.1145/2037373 .2037383\n\n.",
        "Erin Brady, Meredith Morris, Yu Zhong, Samuel White,\n\nand Jeffrey Bigham.",
        "2013.",
        "Visual Challenges in the\nEveryday Lives of Blind People.",
        "Proceedings of the\nSIGCHI Conference on Human Factors in Computing\nSystems.",
        "ACM, 2013.",
        "(2013), 2117-2126.",
        "DOT:\nhttp: //dx.doi.org/10.1145/2470654.2481291\n\n.",
        "Justin Cheng and Michael S Bernstein.",
        "2015.",
        "Flock :\n\nHybrid Crowd-Machine Learning Classifiers.",
        "CSCW °15\nProceedings of the 18th ACM Conference on Computer\nSupported Cooperative Work & Social Computing\n(2015).",
        ".",
        "Justin Cheng, Jaime Teevan, Shamsi Iqbal, and Michael\n\nBernstein.",
        "2015.",
        "Break It Down: A Comparison of\nMacro- and Microtasks.",
        "Proceedings of the 33rd Annual\nACM Conference on Human Factors in Computing\nSystems.",
        "ACM, 2015.",
        "(2015), 4061-4064.\n\n.",
        "Otto Chrons and Sami Sundell.",
        "2011.",
        "Digitalkoot:\n\nMaking Old Archives Accessible Using Crowdsourcing.",
        "Human Computation.",
        "2011, (2011), 20-25.\n\nhttp: //cdn.microtask.com/research/\nDigitalkoot—HCOMP2011-—Chrons-Sundell.pdf\n\n.",
        "Gabriel de la Cruz, Bei Peng, Walter Lasecki, and\n\nMatthew Taylor.",
        "2015.",
        "Towards Integrating Real-Time\nCrowd Advice with Reinforcement Learning.",
        "Proceedings of the 20th International Conference on\nIntelligent User Interfaces Companion.",
        "ACM, 2015.",
        "(2015), 17-20.",
        "DOI:\n\nhttp: //dx.doi.org/10.1145/2732158 .2732180\n\n.",
        "Sebastian Deterding and Dan Dixon.",
        "2011.",
        "From Game\n\nDesign Elements to Gamefulness: Defining\n*Gamification”.",
        "Proceedings of the 15th International\nAcademic MindTrek Conference.",
        "ACM, 20/1.",
        "(2011),\n9-15.",
        "DOI:\n\nhttp: //dx.doi.org/10.1145/2181037.2181040\n\n.",
        "Anhai Doan, Raghu Ramakrishnan, and Alon Halevy.",
        "2011.",
        "Crowdsourcing Systems on the World-Wide Web.",
        "Communications of the ACM 54.4 (2011).",
        "54, 4 (2011),\n86-96.",
        "DOL:\n\nhttp: //dx.doi.org/10.1145/1924421.1924442\n\nCarsten Eickhoff, Christopher G. Harris, Arjen P. de\n\nVries, and Padmini Srinivasan.",
        "2012.",
        "Quality Through\nFlow and Immersion: Gamifying Crowdsourced\n\n41\n\n11.",
        "12.",
        "13.",
        "14.",
        "15.",
        "16.",
        "17.",
        "18.",
        "19.",
        "March 7-10, 2016, Sonoma, CA, USA\n\nRelevance Assessments.",
        "Proceedings of the 35th\nInternational ACM SIGIR Conference on Research and\nDevelopment in Information Retrieval.",
        "ACM, 2012.",
        "(2012), 871.",
        "DOL:\n\nhttp: //dx.doi.org/10.1145/2348283 .2348400\n\nDaniel Esser, Klemens Muthmann, and Daniel Schuster.",
        "2013.",
        "Information Extraction Efficiency of Business\nDocuments Captured with Smartphones and Tablets.",
        "Proceedings of the 2013 ACM Symposium on Document\nEngineering.",
        "ACM, 2013.",
        "(2013), 111-114.",
        "DOI:\n\nhttp: //dx.doi.org/10.1145/2494266.2494302\n\nPaula Estrella and Pablo Paliza.",
        "2014.",
        "OCR Correction\nof Documents Generated during Argentina’s National\nReorganization Process.",
        "Proceedings of the First\n\nInternational Conference on Digital Access to Textual\nCultural Heritage.",
        "ACM, 2014.",
        "(2014), 119-123.",
        "Oluwaseyi Feyisetan, Elena Simperl, Max Van Kleek,\nand Nigel Shadbolt.",
        "2015.",
        "Improving Paid Microtasks\nthrough Gamification and Adaptive Furtherance\nIncentives.",
        "Proceedings of the 24th International\nConference on World Wide Web.",
        "International World\nWide Web Conferences Steering Committee, 2015.",
        "(2015), 333-343.",
        "Juho Hamari and Harri Sarsa.",
        "2014.",
        "Does Gamification\nWork ?",
        "A Literature Review of Empirical Studies on\nGamification.",
        "47th Hawaii International Conference on\nSystem Sciences.",
        "IEEE, 2014 (2014), 3025-3034.",
        "DOT:\nhttp: //dx.doi.org/10.1109/HICSS.2014.377\n\nRose Holley.",
        "2009a.",
        "How Good Can It Get?",
        "Analysing\nand Improving OCR Accuracy in Large Scale Historic\nNewspaper Digitisation Programs.",
        "D-Lib Magazine\n15.3/4 (2009) (2009).",
        "DOI:\n\nhttp: //dx.doi.org/10.1017/CBO9781107415324.004\n\nRose Holley.",
        "2009b.",
        "Many Hands Make Light Work :\nPublic Collaborative OCR Text Correction in Australian\nHistoric Newspapers.",
        "National Library of Australia Staff\nPapers (2009) March (2009), 1-28.",
        "Chin-Lung Hsu and Hsi-Peng Lu.",
        "2004.",
        "Why do People\nPlay On-Line Games?",
        "An Extended TAM with Social\nInfluences and Flow Experience.",
        "Information &\nManagement 41.7 (2004).",
        "41, 7 (2004), 853-868.",
        "DOI:\nhttp: //dx.doi.org/10.1016/j.im.2003.08.014\n\nShih-Wen Huang, Pei-Fen Tu, Wai-Tat Fu, and\nMohammad Amanzadeh.",
        "2013.",
        "Leveraging the Crowd\nto Improve Feature-Sentiment Analysis of User\nReviews.",
        "Proceedings of the 2013 International\nConference on Intelligent User Interfaces.",
        "ACM, 2013.",
        "March 1922 (2013), 3-14.",
        "DOI:\n\nhttp: //dx.doi.org/DOI=10 .1145/2449396.2449400\n\nBill Janssen, Eric Saund, Eric Bier, Patricia Wall, and\nMary Ann Sprague.",
        "2012.",
        "Receipts2Go: The Big World\nof Small Documents.",
        "Proceedings of the 2012 ACM\nSymposium on Document Engineering.",
        "ACM, 2012.",
        "(2012), 121—-124.",
        "http: //dl.acm.org/citation.cfm?id=2361381\n\n\nIUI 2016 * Social Media\n\n20.",
        "21.",
        "22.",
        "23.",
        "24.",
        "25.",
        "26.",
        "27.",
        "28.",
        "29.",
        "30.",
        "Frederic Kerber, Pascal Lessel, Maximilian Altmeyer,\nAnnika Kaltenhauser, Christian Neurohr, and Antonio\nKriiger.",
        "2014.",
        "Towards a Novel Digital Household\nAccount Book.",
        "CHI’ 14 Extended Abstracts on Human\nFactors in Computing Systems.",
        "ACM, 2014.",
        "(2014),\n1921-1926.",
        "DOL:\n\nhttp: //dx.doi.org/10.1145/2559206.2581288\n\nPascal Lessel, Maximilian Altmeyer, and Antonio\nKriiger.",
        "2015.",
        "Analysis of Recycling Capabilities of\nIndividuals and Crowds to Encourage and Educate\nPeople to Separate Their Garbage Playfully.",
        "Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems.",
        "ACM, 2015.",
        "(2015),\n1095-1104.",
        "DOL:\n\nhttp: //dx.doi.org/10.1145/2702123.2702309\n\nPascal Lessel, Maximilian Altmeyer, Marc Miiller,\nChristian Wolff, and Antonio Kriiger.",
        "2016.",
        "Don’t Whip\nMe With Your Games - Investigating Bottom-Up\nGamification.",
        "Proceedings of the SIGCHI Conference\non Human Factors in Computing Systems.",
        "ACM, 2016.",
        "(2016), (to appear).",
        "DOT:\n\nhttp: //dx.doi.org/10.1145/2858036.2858463\n\nVladimir I. Levenshtein.",
        "1966.",
        "Binary Codes Capable of\nCorrecting Deletions, Insertions, and Reversals.",
        "Vol.",
        "10.",
        "Tan Li, Anind Dey, and Jodi Forlizzi.",
        "2010.",
        "A\nStage-Based Model of Personal Informatics Systems.",
        "Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems.",
        "ACM, 2010.",
        "(2010), 557.",
        "DOL http: //dx.doi.org/10.1145/1753326.1753409\n\nElaine Massung, David Coyle, Kirsten F. Cater, Marc\nJay, and Chris Preist.",
        "2013.",
        "Using Crowdsourcing to\nSupport Pro-Environmental Community Activism.",
        "Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems.",
        "ACM, 2013.",
        "(2013),\n371-380.",
        "DOT:\n\nhttp: //dx.doi.org/10.1145/2470654 .2470708\n\nGiinter Miihlberger, Johannes Zelger, and David\nSagmeister.",
        "2014.",
        "User-Driven Correction of OCR\nErrors: Combining Crowdsourcing and Information\nRetrieval Technology.",
        "Proceedings of the First\nInternational Conference on Digital Access to Textual\nCultural Heritage.",
        "ACM, 2014.",
        "52, 1 (2014), 53-56.",
        "M.P.",
        "Nevetha and A. Baskar.",
        "2015.",
        "Applications of Text\nDetection and its Challenges : A Review.",
        "Proceedings of\nthe Third International Symposium on Women in\nComputing and Informatics.",
        "ACM, 2015.",
        "(2015),\n712-721.",
        "Jakob Nielsen.",
        "1992.",
        "Evaluating the Thinking-Aloud\nTechnique for Use by Computer Scientists.",
        "(1992).",
        "Jakob Nielsen.",
        "2000.",
        "Why You Only Need to Test with 5\nUsers.",
        "(2000).",
        "Bahareh Rahmanian and Joseph G. Davis.",
        "2014.",
        "User\nInterface Design for Crowdsourcing Systems.",
        "Proceedings of the 2014 International Working\nConference on Advanced Visual Interfaces - AVI ’14\n\n(2014), 405-408.",
        "DOI:\nhttp: //dx.doi.org/10.1145/2598153 .2602248\n\n42\n\n31.",
        "32.",
        "33.",
        "34.",
        "35.",
        "36.",
        "37.",
        "38.",
        "39.",
        "40.",
        "March 7-10, 2016, Sonoma, CA, USA\n\nCharalampos Saitis, Andrew Hankinson, and Ichiro\nFujinaga.",
        "2014.",
        "Correcting Large-Scale OMR Data with\nCrowdsourcing Categories and Subject Descriptors.",
        "Proceedings of the 1st International Workshop on\nDigital Libraries for Musicology (2014), 1-3.",
        "Zhinian Shen and Yuri Tijerino.",
        "2012.",
        "Ontology-Based\nAutomatic Receipt Accounting System.",
        "International\nConferences on Web Intelligence and Intelligent Agent\nTechnology (WI-IAT), 2012 IEEE/WIC/ACM.",
        "Vol.",
        "3.",
        "IEEE, 2012 (2012), 236-239.",
        "DOT:\n\nhttp: //dx.doi.org/10.1109/WI-IAT.2012.265\n\nStephen Snow and Vyas Dhaval.",
        "2015.",
        "Fixing the\nAlignment: An Exploration of Budgeting Practices in\nthe Home.",
        "Proceedings of the 33rd Annual ACM\nConference Extended Abstracts on Human Factors in\nComputing Systems.",
        "ACM, 2015.",
        "(2015), 2271-2276.",
        "James Surowiecki.",
        "2005.",
        "The Wisdom of Crowds.",
        "Anchor.",
        "Takumi Toyama, Daniel Sonntag, Andreas Dengel,\nTakahiro Matsuda, Masakazu Iwamura, and Koichi\nKise.",
        "2014.",
        "A Mixed Reality Head-Mounted Text\nTranslation System Using Eye Gaze Input.",
        "Proceedings\nof the 19th International Conference on Intelligent User\nInterfaces.",
        "ACM, 2014.",
        "(2014), 329-334.",
        "DOL:\n\nhttp: //dx.doi.org/10.1145/2557500.2557528\n\nLuis von Ahn and Laura Dabbish.",
        "2004.",
        "Labeling\nImages with a Computer Game.",
        "Proceedings of the\nSIGCHI Conference on Human Factors in Computing\nSystems.",
        "ACM, 2004.",
        "(2004), 319 — 326.",
        "DOI:\n\nhttp: //dx.doi.org/10.1145/985692 .",
        "985733\n\nLuis Von Ahn, Benjamin Maurer, Colin McMillen,\nDavid Abraham, and Manuel Blum.",
        "2008.\nreCAPTCHA: Human-Based Character Recognition via\nWeb Security Measures.",
        "Science 321.5895 321, 5895\n(2008), 1465-1468.",
        "DOL:\n\nhttp: //dx.doi.org/10.1126/science.1160379\n\nErika Noll Webb.",
        "2013.",
        "Gamification : When It Works,\nWhen It Doesnt.",
        "Design, User Experience, and\nUsability.",
        "Health, Learning, Playing, Cultural, and\nCross-Cultural User Experience.",
        "Springer Berlin\n\nHeidelberg, 2013 (2013), 608-614.",
        "Mark Whooley, Bernd Ploderer, and Kathleen Gray.",
        "2014.",
        "On the Integration of Self-Tracking Data Amongst\nQuantified Self Members.",
        "Proceedings of the 28th\nInternational BCS Human Computer Interaction\nConference on HCI 2014-Sand, Sea and Sky-Holiday\nHCI.",
        "BCS, 2014.",
        "February (2014), 151-160.",
        "DOL:\nhttp: //dx.doi.org/10.14236/ewic/hci2014.16\n\nGuangyu Zhu, Timothy J. Bethea, and Vikas Krishna.",
        "2007.",
        "Extracting Relevant Named Entities for\nAutomated Expense Reimbursement.",
        "Proceedings of the\n13th ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining.",
        "ACM, 2007.",
        "(2007), 1004-1012.",
        "DOT:\n\nhttp: //dx.doi.org/10.1145/1281192.1281300"
    ],
    "provenance_size": 16612,
    "tokens": [
        88060,
        20030
    ],
    "provenance_ids": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        180,
        181,
        182,
        183,
        184,
        185,
        186,
        187,
        188,
        189,
        190,
        191,
        192,
        193,
        194,
        195,
        196,
        197,
        198,
        199,
        200,
        201,
        202,
        203,
        204,
        205,
        206,
        207,
        208,
        209,
        210,
        211,
        212,
        213,
        214,
        215,
        216,
        217,
        218,
        219,
        220,
        221,
        222,
        223,
        224,
        225,
        226,
        227,
        228,
        229,
        230,
        231,
        232,
        233,
        234,
        235,
        236,
        237,
        238,
        239,
        240,
        241,
        242,
        243,
        244,
        245,
        246,
        247,
        248,
        249,
        250,
        251,
        252,
        253,
        254,
        255,
        256,
        257,
        258,
        259,
        260,
        261,
        262,
        263,
        264,
        265,
        266,
        267,
        268,
        269,
        270,
        271,
        272,
        273,
        274,
        275,
        276,
        277,
        278,
        279,
        280,
        281,
        282,
        283,
        284,
        285,
        286,
        287,
        288,
        289,
        290,
        291,
        292,
        293,
        294,
        295,
        296,
        297,
        298,
        299,
        300,
        301,
        302,
        303,
        304,
        305,
        306,
        307,
        308,
        309,
        310,
        311,
        312,
        313,
        314,
        315,
        316,
        317,
        318,
        319,
        320,
        321,
        322,
        323,
        324,
        325,
        326,
        327,
        328,
        329,
        330,
        331,
        332,
        333,
        334,
        335,
        336,
        337,
        338,
        339,
        340,
        341,
        342,
        343,
        344,
        345,
        346,
        347,
        348,
        349,
        350,
        351,
        352,
        353,
        354,
        355,
        356,
        357,
        358,
        359,
        360,
        361,
        362,
        363,
        364,
        365,
        366,
        367,
        368,
        369,
        370,
        371,
        372,
        373,
        374,
        375,
        376,
        377,
        378,
        379,
        380,
        381,
        382,
        383,
        384,
        385,
        386,
        387,
        388,
        389,
        390,
        391,
        392,
        393,
        394,
        395,
        396,
        397,
        398,
        399,
        400,
        401,
        402,
        403,
        404,
        405,
        406,
        407,
        408,
        409,
        410,
        411,
        412,
        413,
        414,
        415,
        416,
        417,
        418,
        419,
        420,
        421,
        422,
        423,
        424,
        425,
        426,
        427,
        428,
        429,
        430,
        431,
        432,
        433,
        434,
        435,
        436,
        437,
        438,
        439,
        440,
        441,
        442,
        443,
        444,
        445,
        446,
        447,
        448,
        449,
        450,
        451,
        452,
        453,
        454,
        455,
        456,
        457,
        458,
        459,
        460,
        461,
        462,
        463,
        464,
        465,
        466,
        467,
        468,
        469,
        470,
        471,
        472,
        473,
        474,
        475,
        476,
        477,
        478,
        479,
        480,
        481,
        482,
        483,
        484,
        485,
        486,
        487,
        488,
        489,
        490,
        491,
        492,
        493,
        494,
        495,
        496,
        497,
        498,
        499,
        500,
        501,
        502,
        503,
        504,
        505,
        506,
        507,
        508,
        509,
        510,
        511,
        512,
        513,
        514,
        515,
        516,
        517,
        518,
        519,
        520,
        521,
        522,
        523,
        524,
        525,
        526,
        527,
        528,
        529,
        530,
        531,
        532,
        533,
        534,
        535,
        536,
        537,
        538,
        539,
        540,
        541,
        542,
        543,
        544,
        545,
        546,
        547,
        548,
        549,
        550,
        551,
        552,
        553,
        554,
        555,
        556,
        557,
        558,
        559,
        560,
        561,
        562,
        563,
        564,
        565,
        566,
        567,
        568,
        569,
        570,
        571,
        572,
        573,
        574,
        575,
        576,
        577,
        578,
        579,
        580,
        581,
        582,
        583,
        584,
        585,
        586,
        587,
        588,
        589,
        590,
        591,
        592,
        593,
        594,
        595,
        596,
        597,
        598,
        599,
        600,
        601,
        602,
        603,
        604,
        605,
        606,
        607,
        608,
        609,
        610,
        611,
        612,
        613,
        614,
        615,
        616,
        617,
        618,
        619,
        620,
        621,
        622,
        623,
        624,
        625,
        626,
        627,
        628,
        629,
        630,
        631,
        632,
        633,
        634,
        635,
        636,
        637,
        638,
        639,
        640,
        641,
        642,
        643,
        644,
        645,
        646,
        647,
        648,
        649,
        650,
        651,
        652,
        653,
        654,
        655,
        656,
        657,
        658,
        659,
        660,
        661,
        662,
        663,
        664,
        665,
        666,
        667,
        668,
        669,
        670,
        671,
        672,
        673,
        674,
        675,
        676,
        677,
        678,
        679
    ]
}
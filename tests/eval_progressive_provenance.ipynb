{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yiminglin/Documents/Codebase/doc-provenance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yiminglin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parent_directory = str(Path().resolve().parent)\n",
    "parent_directory\n",
    "\n",
    "import os,sys \n",
    "script_path = os.path.abspath(\"../src\")  # Adjust the path\n",
    "sys.path.append(script_path)\n",
    "print(parent_directory)\n",
    "import doc_provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import tiktoken\n",
    "\n",
    "def read_json(path):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    encoder = tiktoken.encoding_for_model(model)  # Get the tokenizer for the specific model\n",
    "    tokens = encoder.encode(text)  # Encode text into tokens\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '\"I Don\\'t Understand...\" Issues in Self-Quantifying Commuting', 'question': ['In what year was this paper published?', 'Return only a number. Do not add explanations.'], 'answers': ['2019'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc0_q0_divide_and_conquer_progressive.json', 'context_size': 5912, 'time': 18.206860065460205, 'time_breakdown': {'0': 3.425351142883301, '1': 5.61928915977478, '2': 9.694602966308594, '3': 14.777266263961792, '4': 18.206812143325806}, 'tokens': [26563, 113], 'tokens_breakdown': {'0': [12887, 16], '1': [13871, 24], '2': [15737, 72], '3': [25395, 92], '4': [26563, 113]}, 'provenance_ids_breakdown': {'0': [6], '1': [15], '2': [32], '3': [113], '4': [93]}}, {'title': '\"I Don\\'t Understand...\" Issues in Self-Quantifying Commuting', 'question': ['Who are the authors of this paper?', 'Return only the author names. Do not add explanations.'], 'answers': ['Cecile Boulard, Stefania Castellani, Tommaso Colombino, Antonietta Grasso'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc0_q1_divide_and_conquer_progressive.json', 'context_size': 5912, 'time': 10.203498125076294, 'time_breakdown': {'0': 7.5308287143707275}, 'tokens': [18143, 219], 'tokens_breakdown': {'0': [12579, 132]}, 'provenance_ids_breakdown': {'0': [4]}}, {'title': '\"I Don\\'t Understand...\" Issues in Self-Quantifying Commuting', 'question': ['In which conference was this paper published?', 'Return only the conference name. Do not add explanations.'], 'answers': ['ECCE 2019'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc0_q2_divide_and_conquer_progressive.json', 'context_size': 5912, 'time': 40.783703088760376, 'time_breakdown': {'0': 12.10587191581726, '1': 17.021498918533325, '2': 24.18935799598694, '3': 33.70758295059204, '4': 40.78365898132324}, 'tokens': [26598, 318], 'tokens_breakdown': {'0': [12895, 124], '1': [13883, 150], '2': [15757, 213], '3': [25425, 270], '4': [26598, 318]}, 'provenance_ids_breakdown': {'0': [5, 6, 7], '1': [14], '2': [32], '3': [113], '4': [93]}}, {'title': 'Expense Control: A Gamified, Semi-Automated, Crowd-Based Approach For Receipt Capturing', 'question': ['In what year was this paper published?', 'Return only a number. Do not add explanations.'], 'answers': ['2016'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc1_q0_divide_and_conquer_progressive.json', 'context_size': 16907, 'time': 18.610977172851562, 'time_breakdown': {'0': 4.256409168243408, '1': 7.041366100311279, '2': 10.829507112503052, '3': 13.190688133239746, '4': 18.610926151275635}, 'tokens': [50564, 66], 'tokens_breakdown': {'0': [37589, 20], '1': [39361, 30], '2': [42568, 42], '3': [44641, 52], '4': [50564, 66]}, 'provenance_ids_breakdown': {'0': [393], '1': [371], '2': [358], '3': [339], '4': [322]}}, {'title': 'Expense Control: A Gamified, Semi-Automated, Crowd-Based Approach For Receipt Capturing', 'question': ['Who are the authors of this paper?', 'Return only the author names. Do not add explanations.'], 'answers': ['Maximilian Altmeyer, Pascal Lessel, Antonio Kr√ºger'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc1_q1_divide_and_conquer_progressive.json', 'context_size': 16907, 'time': 17.695875883102417, 'time_breakdown': {'0': 9.515817880630493}, 'tokens': [52070, 682], 'tokens_breakdown': {'0': [37845, 181]}, 'provenance_ids_breakdown': {'0': [0, 1]}}, {'title': 'Expense Control: A Gamified, Semi-Automated, Crowd-Based Approach For Receipt Capturing', 'question': ['In which conference was this paper published?', 'Return only the conference name. Do not add explanations.'], 'answers': ['IUI 2016'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc1_q2_divide_and_conquer_progressive.json', 'context_size': 16907, 'time': 34.81577277183533, 'time_breakdown': {'0': 10.133339166641235, '1': 15.547941207885742, '2': 22.37788724899292, '3': 28.215618133544922, '4': 34.815723180770874}, 'tokens': [69243, 301], 'tokens_breakdown': {'0': [37599, 53], '1': [41552, 103], '2': [48402, 160], '3': [51427, 227], '4': [69243, 301]}, 'provenance_ids_breakdown': {'0': [393], '1': [358], '2': [322], '3': [284], '4': [243]}}, {'title': 'Understanding My Data, Myself: Supporting Self-reflection with Ubicomp Technologies', 'question': ['In what year was this paper published?', 'Return only a number. Do not add explanations.'], 'answers': ['2011'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc2_q0_divide_and_conquer_progressive.json', 'context_size': 13064, 'time': 31.224936962127686, 'time_breakdown': {'0': 8.485649824142456, '1': 12.052831888198853, '2': 15.841678857803345, '3': 23.00777578353882, '4': 31.22486400604248}, 'tokens': [35575, 69], 'tokens_breakdown': {'0': [26491, 16], '1': [27203, 24], '2': [28202, 32], '3': [30866, 46], '4': [35575, 69]}, 'provenance_ids_breakdown': {'0': [14], '1': [0], '2': [15], '3': [57], '4': [107]}}, {'title': 'Understanding My Data, Myself: Supporting Self-reflection with Ubicomp Technologies', 'question': ['Who are the authors of this paper?', 'Return only the author names. Do not add explanations.'], 'answers': ['Ian Li, Anind K. Dey, Jodi Forlizzi'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc2_q1_divide_and_conquer_progressive.json', 'context_size': 13064, 'time': 9.801861047744751, 'time_breakdown': {'1': 6.713112831115723}, 'tokens': [39267, 276], 'tokens_breakdown': {'1': [26913, 148]}, 'provenance_ids_breakdown': {'1': [0]}}, {'title': 'Understanding My Data, Myself: Supporting Self-reflection with Ubicomp Technologies', 'question': ['In which conference was this paper published?', 'Return only the conference name. Do not add explanations.'], 'answers': [\"UbiComp'11\"], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc2_q2_divide_and_conquer_progressive.json', 'context_size': 13064, 'time': 38.408461809158325, 'time_breakdown': {'0': 8.511884927749634, '1': 16.082127809524536, '2': 25.4010910987854, '3': 31.592472076416016, '4': 38.40840196609497}, 'tokens': [46095, 271], 'tokens_breakdown': {'0': [26913, 55], '1': [29832, 87], '2': [34327, 170], '3': [41776, 223], '4': [46095, 271]}, 'provenance_ids_breakdown': {'0': [0], '1': [57], '2': [107], '3': [154], '4': [202]}}, {'title': 'Sundroid: Solar Radiation Awareness with Smartphones', 'question': ['In what year was this paper published?', 'Return only a number. Do not add explanations.'], 'answers': ['2011'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc3_q0_divide_and_conquer_progressive.json', 'context_size': 12329, 'time': 29.615509033203125, 'time_breakdown': {'0': 6.511491060256958, '1': 10.401652097702026, '2': 15.92332124710083, '3': 23.927191019058228, '4': 29.61546802520752}, 'tokens': [43559, 109], 'tokens_breakdown': {'0': [24768, 18], '1': [26022, 53], '2': [31432, 71], '3': [39125, 89], '4': [43559, 109]}, 'provenance_ids_breakdown': {'0': [17], '1': [0], '2': [62], '3': [193], '4': [137]}}, {'title': 'Sundroid: Solar Radiation Awareness with Smartphones', 'question': ['Who are the authors of this paper?', 'Return only the author names. Do not add explanations.'], 'answers': ['Thomas Fahrni, Michael Kuhn, Philipp Sommer, Roger Wattenhofer, Samuel Welten'], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc3_q1_divide_and_conquer_progressive.json', 'context_size': 12329, 'time': 12.196069955825806, 'time_breakdown': {'2': 8.942065000534058}, 'tokens': [36733, 265], 'tokens_breakdown': {'2': [24927, 178]}, 'provenance_ids_breakdown': {'2': [0]}}, {'title': 'Sundroid: Solar Radiation Awareness with Smartphones', 'question': ['In which conference was this paper published?', 'Return only the conference name. Do not add explanations.'], 'answers': [\"UbiComp'11\"], 'path': '/Users/yiminglin/Documents/Codebase/doc-provenance/out/papers/results/doc3_q2_divide_and_conquer_progressive.json', 'context_size': 12329, 'time': 38.06829309463501, 'time_breakdown': {'0': 7.789639949798584, '1': 15.033282995223999, '2': 21.586835861206055, '3': 28.447901010513306, '4': 38.068262815475464}, 'tokens': [54846, 362], 'tokens_breakdown': {'0': [26254, 59], '1': [33735, 126], '2': [38217, 192], '3': [40817, 274], '4': [54846, 362]}, 'provenance_ids_breakdown': {'0': [341], '1': [306], '2': [265], '3': [231], '4': [193]}}]\n"
     ]
    }
   ],
   "source": [
    "#paper dataset \n",
    "data_path = parent_directory + '/out/papers/results/'\n",
    "strategies = ['vallina_LLM','sequential_greedy','divide_and_conquer','heuristic_greedy','heuristic_topk','exponential_greedy','divide_and_conquer_progressive']\n",
    "strategy = 'divide_and_conquer_progressive'\n",
    "\n",
    "doc_num = 4\n",
    "q_num = 3\n",
    "runs = {}\n",
    "for d_id in range(doc_num):\n",
    "    for q_id in range(q_num):\n",
    "        #this is one run \n",
    "        file_path = data_path + 'doc' + str(d_id) + '_q' + str(q_id) + '_' + strategy + '.json'\n",
    "        result = read_json(file_path)\n",
    "        if(result == None):\n",
    "            continue\n",
    "        if strategy not in runs:\n",
    "            runs[strategy] = []\n",
    "        runs[strategy].append(result) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 top1_time: 3.425351142883301 total_time: 18.206812143325806 top1_cost: 0.00194265 total_cost: 0.004052249999999999\n",
      "1 top1_time: 7.5308287143707275 total_time: 7.5308287143707275 top1_cost: 0.00196605 total_cost: 0.00196605\n",
      "5 top1_time: 4.256409168243408 total_time: 18.610926151275635 top1_cost: 0.005650349999999999 total_cost: 0.007624199999999999\n",
      "1 top1_time: 9.515817880630493 total_time: 9.515817880630493 top1_cost: 0.00578535 total_cost: 0.00578535\n",
      "5 top1_time: 8.485649824142456 total_time: 31.22486400604248 top1_cost: 0.00398325 total_cost: 0.0053776499999999994\n",
      "5 top1_time: 8.511884927749634 total_time: 38.40840196609497 top1_cost: 0.00406995 total_cost: 0.007076849999999999\n",
      "5 top1_time: 6.511491060256958 total_time: 29.61546802520752 top1_cost: 0.0037259999999999997 total_cost: 0.00659925\n",
      "5 top1_time: 7.789639949798584 total_time: 38.068262815475464 top1_cost: 0.0039735 total_cost: 0.0084441\n",
      "4.0 7.003384083509445 23.897672712802887 0.0038871374999999994 0.005865712499999998\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "input_cost_unit = 0.15/1000000\n",
    "output_cost_unit = 0.6/1000000\n",
    "\n",
    "sum_top1_time = 0\n",
    "sum_total_time = 0\n",
    "sum_top1_cost = 0\n",
    "sum_total_cost = 0\n",
    "sum_k = 0\n",
    "\n",
    "for run in runs[strategy]:\n",
    "    time_breakdown = run['time_breakdown']\n",
    "    tokens_breakdown = run['tokens_breakdown']\n",
    "    k = len(tokens_breakdown)\n",
    "    if k == 0:\n",
    "        continue\n",
    "    # print(tokens_breakdown)\n",
    "    # print(time_breakdown)\n",
    "    if '0' not in time_breakdown:\n",
    "        continue\n",
    "    top1_time = time_breakdown['0']\n",
    "    top1_cost = input_cost_unit*tokens_breakdown['0'][0] + output_cost_unit*tokens_breakdown['0'][1]\n",
    "    total_time = time_breakdown[str(k-1)]\n",
    "    total_cost = input_cost_unit*tokens_breakdown[str(k-1)][0] + output_cost_unit*tokens_breakdown[str(k-1)][1]\n",
    "    \n",
    "    if top1_time > 10:\n",
    "        continue\n",
    "    print(k, 'top1_time:',top1_time,'total_time:',total_time,'top1_cost:',top1_cost,'total_cost:',total_cost)\n",
    "    sum_top1_time += top1_time\n",
    "    sum_total_time += total_time\n",
    "    sum_top1_cost += top1_cost\n",
    "    sum_total_cost += total_cost\n",
    "    sum_k += k\n",
    "    c+=1\n",
    "    #break\n",
    "avg_top1_time = sum_top1_time/c\n",
    "avg_total_time = sum_total_time/c\n",
    "avg_top1_cost = sum_top1_cost/c\n",
    "avg_total_cost = sum_total_cost/c\n",
    "avg_k = sum_k/c\n",
    "\n",
    "print(avg_k, avg_top1_time,avg_total_time,avg_top1_cost,avg_total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hotpot dataset \n",
    "data_path = parent_directory + '/out/hotpotQA/results/'\n",
    "strategies = ['vallina_LLM','sequential_greedy','divide_and_conquer','heuristic_greedy','heuristic_topk','exponential_greedy','divide_and_conquer_progressive']\n",
    "strategy = 'divide_and_conquer_progressive'\n",
    "\n",
    "\n",
    "q_num = 12\n",
    "runs = {}\n",
    "for q_id in range(q_num):\n",
    "    #this is one run \n",
    "    file_path = data_path + 'hotpot' + '_q' + str(q_id) + '_' + strategy + '.json'\n",
    "    result = read_json(file_path)\n",
    "    if strategy not in runs:\n",
    "        runs[strategy] = []\n",
    "    runs[strategy].append(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 top1_time: 1.9364728927612305 total_time: 6.123777866363525 top1_cost: 0.00025739999999999997 total_cost: 0.00041699999999999994\n",
      "1 top1_time: 6.022511959075928 total_time: 6.022511959075928 top1_cost: 0.00039855 total_cost: 0.00039855\n",
      "1 top1_time: 2.9472336769104004 total_time: 2.9472336769104004 top1_cost: 0.0005778000000000001 total_cost: 0.0005778000000000001\n",
      "5 top1_time: 2.791282892227173 total_time: 11.525734186172485 top1_cost: 0.0008013 total_cost: 0.00122445\n",
      "4 top1_time: 4.159999847412109 total_time: 10.54534387588501 top1_cost: 0.00046619999999999995 total_cost: 0.0006266999999999999\n",
      "5 top1_time: 4.366109848022461 total_time: 16.207197189331055 top1_cost: 0.00045929999999999994 total_cost: 0.0006603\n",
      "5 top1_time: 6.016167879104614 total_time: 24.559802770614624 top1_cost: 0.0004881 total_cost: 0.0010134\n",
      "1 top1_time: 4.546765089035034 total_time: 4.546765089035034 top1_cost: 0.00033224999999999997 total_cost: 0.00033224999999999997\n",
      "3.25 4.098318010568619 10.309795826673508 0.00047261250000000003 0.00065630625\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "input_cost_unit = 0.15/1000000\n",
    "output_cost_unit = 0.6/1000000\n",
    "\n",
    "sum_top1_time = 0\n",
    "sum_total_time = 0\n",
    "sum_top1_cost = 0\n",
    "sum_total_cost = 0\n",
    "sum_k = 0\n",
    "\n",
    "for run in runs[strategy]:\n",
    "    time_breakdown = run['time_breakdown']\n",
    "    tokens_breakdown = run['tokens_breakdown']\n",
    "    k = len(tokens_breakdown)\n",
    "    if k == 0:\n",
    "        continue\n",
    "    # print(tokens_breakdown)\n",
    "    # print(time_breakdown)\n",
    "    if '0' not in time_breakdown:\n",
    "        continue\n",
    "    top1_time = time_breakdown['0']\n",
    "    top1_cost = input_cost_unit*tokens_breakdown['0'][0] + output_cost_unit*tokens_breakdown['0'][1]\n",
    "    total_time = time_breakdown[str(k-1)]\n",
    "    total_cost = input_cost_unit*tokens_breakdown[str(k-1)][0] + output_cost_unit*tokens_breakdown[str(k-1)][1]\n",
    "    \n",
    "    if top1_time > 10:\n",
    "        continue\n",
    "    print(k, 'top1_time:',top1_time,'total_time:',total_time,'top1_cost:',top1_cost,'total_cost:',total_cost)\n",
    "    sum_top1_time += top1_time\n",
    "    sum_total_time += total_time\n",
    "    sum_top1_cost += top1_cost\n",
    "    sum_total_cost += total_cost\n",
    "    sum_k += k\n",
    "    c+=1\n",
    "    #break\n",
    "avg_top1_time = sum_top1_time/c\n",
    "avg_total_time = sum_total_time/c\n",
    "avg_top1_cost = sum_top1_cost/c\n",
    "avg_total_cost = sum_total_cost/c\n",
    "avg_k = sum_k/c\n",
    "\n",
    "print(avg_k, avg_top1_time,avg_total_time,avg_top1_cost,avg_total_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
